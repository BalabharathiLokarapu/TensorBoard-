dist: xenial
language: python
python:
  - "3.6"
  - "2.7"

branches:
  only:
    - master
    - /^\d+\.\d+(\.\d+)?(-\S*)?$/

env:
  # Keep this Bazel version in sync with the `versions.check` directive
  # near the top of our WORKSPACE file.
  #
  # Grab the BAZEL_SHA256SUM from the Bazel releases page; e.g.:
  # bazel-0.20.0-linux-x86_64.sha256
  global:
    - BAZEL=0.26.1
    - BAZEL_SHA256SUM=6c50e142a0a405d3d8598050d6c1b3920c8cdb82a7ffca6fc067cb474275148f
    - BUILDIFIER=0.29.0
    - BUILDIFIER_SHA256SUM=4c985c883eafdde9c0e8cf3c8595b8bfdf32e77571c369bf8ddae83b042028d6
  matrix:
    - TF_VERSION_ID=tensorflow==1.15.0rc3
    - TF_VERSION_ID=tf-nightly
    - TF_VERSION_ID=  # Do not install TensorFlow in this case

cache:
  # Reuse the pip cache directory across build machines.
  pip: true
  # Cache directories for Bazel. See ci/bazelrc for details.
  directories:
    - $HOME/.cache/tb-bazel-repo
    - $HOME/.cache/tb-bazel-disk

# Each bullet point is displayed in the Travis log as one collapsed line, which
# indicates how long it took. Travis will check the return code at the end. We
# can't use `set -e` in the YAML file since it might impact Travis internals.
# If inline scripts get too long, Travis surprisingly prints them twice.

before_install:
  - elapsed() { TZ=UTC printf "Time %(%T)T %s\n" "$SECONDS" "$1"; }
  - elapsed "before_install"
  - ci/download_bazel.sh "${BAZEL}" "${BAZEL_SHA256SUM}" ~/bazel
  - sudo mv ~/bazel /usr/local/bin/bazel
  - ci/download_buildifier.sh "${BUILDIFIER}" "${BUILDIFIER_SHA256SUM}" ~/buildifier
  - sudo mv ~/buildifier /usr/local/bin/buildifier
  - cp ci/bazelrc ~/.bazelrc
  - elapsed "before_install (done)"

install:
  - elapsed "install"
  - "PY3=\"$(python -c 'if __import__(\"sys\").version_info[0] > 2: print(1)')\""
  # Older versions of Pip sometimes resolve specifiers like `tf-nightly`
  # to versions other than the most recent(!).
  - pip install -U pip
  # Uninstall older Travis numpy to avoid upgrade-in-place issues.
  - pip uninstall -y numpy
  - |
    pip install \
      -r tensorboard/pip_package/requirements.txt \
      -r tensorboard/pip_package/requirements_dev.txt \
      ;
  - yarn install --ignore-engines
  - |
    # Install TensorFlow if requested
    if [ -n "${TF_VERSION_ID}" ]; then
      pip install -I "${TF_VERSION_ID}"
    fi
  # Workaround for https://github.com/travis-ci/travis-ci/issues/7940
  - sudo rm -f /etc/boto.cfg
  - pip freeze  # print installed distributions, for debugging purposes
  - elapsed "install (done)"

before_script:
  - elapsed "before_script"
  # Do a fail-fast check for Python syntax errors or undefined names.
  # See: http://flake8.pycqa.org/en/3.7.8/user/error-codes.html
  # Use the comment '# noqa: <error code>' to suppress.
  - flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
  # Lint frontend code
  - yarn lint
  # Lint backend code
  - if [ -n "${PY3}" ]; then black --check .; fi
  # Lint .yaml docs files. Use '# yamllint disable-line rule:foo' to suppress.
  - yamllint -c docs/.yamllint docs docs/.yamllint
  # Lint BUILD files
  - git ls-files -z '*BUILD' | xargs -0 buildifier --mode=check
  # Make sure that IPython notebooks have valid Markdown.
  - tensorboard/tools/docs_list_format_test.sh
  # Make sure we aren't accidentally including work-in-progress code.
  - tensorboard/tools/do_not_submit_test.sh
  # Make sure all necessary files have the license information.
  - tensorboard/tools/license_test.sh
  # Make sure that build URLs are valid.
  - tensorboard/tools/mirror_urls_test.sh
  # Make sure that files have no trailing whitespace.
  - tensorboard/tools/whitespace_hygiene_test.py
  - |
    # Specify subset of tests to run depending on TF installation config.
    # We condition the value of --test_tag_filters so that we can run the
    # bazel test command unconditionally which produces nicer log output.
    if [ -z "${TF_VERSION_ID}" ]; then
      test_tag_filters=support_notf
    else
      test_tag_filters=
    fi
  - elapsed "before_script (done)"

# Commands in this section should only fail if it's our fault. Travis will
# categorize them as 'failed', rather than 'error' for other sections.
script:
  - elapsed "script"
  # Note: bazel test implies fetch+build, but this gives us timing.
  - elapsed && bazel fetch //tensorboard/...
  - elapsed && bazel build //tensorboard/...
  - elapsed && bazel test //tensorboard/... --test_tag_filters="${test_tag_filters}"
  - elapsed && bazel run //tensorboard/pip_package:test_pip_package -- --default-python-only --tf-version "${TF_VERSION_ID}"
  # Run manual S3 test
  - elapsed && bazel test //tensorboard/compat/tensorflow_stub:gfile_s3_test
  - elapsed && bazel test //tensorboard/summary/writer:event_file_writer_s3_test
  - elapsed "script (done)"

after_script:
  # Bazel launches daemons unless --batch is used.
  - elapsed "after_script"
  - bazel shutdown

notifications:
  email: false
