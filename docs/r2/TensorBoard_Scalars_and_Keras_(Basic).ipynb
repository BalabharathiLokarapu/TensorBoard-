{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorBoard Scalars and Keras (Basic)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "eJhPDPGi2Mds",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorBoard Scalars: Logging basic training metrics in Keras\n",
        "\n",
        "A basic task in machine learning is understanding how key metrics such as loss and accuracy change as training progresses. These metrics can help you understand if you're overfitting, for example, or if you're unnecessarily training for too long. You may also want to compare these metrics across different training runs to help debug and improve your model.\n",
        "\n",
        "TensorFlow's Scalar Summary API allows you to visualize these metrics in TensorBoard with very little effort. This tutorial presents a very basic example to give you an introduction to using Scalar Summaries when developing your Keras model.\n"
      ]
    },
    {
      "metadata": {
        "id": "3U5gdCw_nSG3",
        "colab_type": "code",
        "outputId": "93e18e78-9aaf-4f11-9a2e-63466aca1ea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q tf-nightly-2.0-preview\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard.notebook"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mSkipping tensorboard as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1qIKtOBrqc9Y",
        "colab_type": "code",
        "outputId": "9f005a14-d47f-4509-819a-20ef1499e695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TF version: \", tf.__version__)\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version:  2.0.0-dev20190221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uYuVz-mfq1aB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, start with a clean slate and clear any logs from previous runs."
      ]
    },
    {
      "metadata": {
        "id": "ZthVCS7Nq0HI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf logs/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6YDAoNCN3ZNS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setting up data for regression\n",
        "\n",
        "You're now going to use Keras to calculate a regression, i.e., find the best line of fit for a paired data set. (While using a gradient descent and neural networks is [overkill for this kind of problem](https://https://stats.stackexchange.com/questions/160179/do-we-need-gradient-descent-to-find-the-coefficients-of-a-linear-regression-mode), it does make for a very easy to understand example.)\n",
        "\n",
        "You're going to use TensorBoard to observe how training and test **loss** change across epochs. Hopefully, you'll see training and test loss decrease over time and remain steady.\n",
        "\n",
        "First, generate 1000 data points roughly along the line *y = 0.5x + 2*. Split these data points into training and test sets. The neural net will learn this relationship."
      ]
    },
    {
      "metadata": {
        "id": "j-ryO6OxnQH_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_size = 1000\n",
        "# 80% of our data is for training.\n",
        "train_pct = 0.8\n",
        "\n",
        "train_size = int(data_size * train_pct)\n",
        "\n",
        "X = np.linspace(-1, 1, data_size)\n",
        "np.random.shuffle(X)\n",
        "\n",
        "# f(X) = 0.5X + 2 + noise\n",
        "Y = 0.5 * X + 2 + np.random.normal(0, 0.05, (data_size, ))\n",
        "\n",
        "# Split into test and train data.\n",
        "X_train, Y_train = X[:train_size], Y[:train_size]\n",
        "X_test, Y_test = X[train_size:], Y[train_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDJuNRkhvKWZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Start TensorBoard\n",
        "\n",
        "Now, start TensorBoard. Wait a few seconds for TensorBoard's UI to spin up.\n",
        "\n",
        "You'll see it say that \"No dashboards are active for the current data set\". That's because you haven't\n",
        "logged any data yet in this session. Once you begin training, your Keras model will start logging data. TensorBoard will automatically refresh and show you your scalar metrics."
      ]
    },
    {
      "metadata": {
        "id": "2lkVqdsoqpfD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/scalars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FT5Yo9PKwBRj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To log the loss scalar, create the Keras TensorBoard callback, specifying the log directory as a timestamped subdirectory to allow easy identification and selection of training runs.\n",
        "\n",
        "Pass the TensorBoard callback to Model.fit() [link text](https://https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit).\n",
        "\n",
        "Once you've started training, scroll back up to TensorBoard and watch as the scalar graphs update.\n",
        "\n",
        "You can zoom in and out of the graphs with your mouse, or select part of them to view more detail. Notice that both training and validation loss curves are overlaid for easy comparison. Things appear to have progressed well during training. In fact, you could have stopped training after 25 epochs or steps, because the training didn't improve after that point. \n"
      ]
    },
    {
      "metadata": {
        "id": "hg5eg7jWqWg_",
        "colab_type": "code",
        "outputId": "8471dab4-2ad1-40fc-bb85-804e75b4030c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "logdir=\"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(2048, input_dim=1),\n",
        "    keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='mse', # keras.losses.mean_squared_error\n",
        "    optimizer=keras.optimizers.SGD(lr=0.2),\n",
        ")\n",
        "\n",
        "print(\"Training ... This takes less than 10 seconds.\")\n",
        "training_history = model.fit(\n",
        "    X_train, # input\n",
        "    Y_train, # output\n",
        "    batch_size=train_size,\n",
        "    verbose=0, # Suppress chatty output; we're going to look at Tensorboard\n",
        "    epochs=100,\n",
        "    validation_data=(X_test, Y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        ")\n",
        "\n",
        "print(\"Average test loss: \", np.average(training_history.history['loss']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training ... This takes less than 10 seconds.\n",
            "Average test loss:  0.04592571808258072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "finK0GfYyefe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Try out the model\n",
        "\n",
        "Ok, the metrics look good! Now see how the model actually behaves in real life. \n",
        "\n",
        "Given the input data (60, 25, 2), the line *y = 0.5x + 2* should yield (32, 14.5, 3). Does the model agree?"
      ]
    },
    {
      "metadata": {
        "id": "EuiLgxQstt32",
        "colab_type": "code",
        "outputId": "0677858a-2d53-4c9d-938b-e41cb6f666cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.predict([60, 25, 2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[31.967478 ]\n",
            " [14.485809 ]\n",
            " [ 2.9978569]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bom4MdeewRKS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Not bad!"
      ]
    }
  ]
}