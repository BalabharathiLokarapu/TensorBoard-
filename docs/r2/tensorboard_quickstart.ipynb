{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorboard_quickstart.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "SB93Ge748VQs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "metadata": {
        "id": "0sK8X2O9bTlz",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HEYuO5NFwDK9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorBoard Quickstart\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/not_a_real_link\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />WIP</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/r2/quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorboard/blob/master/docs/r2/quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "56V5oun18ZdZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In machine learning, to improve something we often need to be able to measure it. TensorBoard is a tool for providing the measurements and visualizations needed during the machine learning workflow. It enables tracking experiment metrics like loss and accuracy, visualizing the model graph, projecting embeddings to a lower dimensional space, and much more.\n",
        "\n",
        "This quickstart will show how to quickly get started with TensorBoard. The remaining guides in this website provide more details on specific capabilities, many of which are not included here. "
      ]
    },
    {
      "metadata": {
        "id": "6B95Hb6YVgPZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tf-nightly-2.0-preview\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard.notebook "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_wqSAZExy6xV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ao7fJW1Pyiza",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z5pr9vuHVgXY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're using the [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist) dataset as our example. "
      ]
    },
    {
      "metadata": {
        "id": "j-DHsby18cot",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "def create_model():\n",
        "  return tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XKUjdIoV87um",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using TensorBoard with Keras Model.fit()"
      ]
    },
    {
      "metadata": {
        "id": "8CL_lxdn8-Sv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When training with Keras's [Model.fit()](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit), adding the TensorBoard callback will ensure logs are created and stored.\n",
        "\n",
        "We place the logs in a timestamped subdirectory to allow easy selection of different training runs."
      ]
    },
    {
      "metadata": {
        "id": "WAQThq539CEJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "log_dir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model.fit(x=x_train, \n",
        "          y=y_train, \n",
        "          epochs=5, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "asjGpmD09dRl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start TensorBoard through the command line or within a notebook experience. The two interfaces are generally the same. In notebooks, we use the `%tensorboard` line magic. In the command line, we would run the same command without \"%\"."
      ]
    },
    {
      "metadata": {
        "id": "A4UKgTLb9fKI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MCsoUNb6YhGc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"images/quickstart_model_fit.png\"/> -->"
      ]
    },
    {
      "metadata": {
        "id": "Gi4PaRm39of2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A brief overview of the plugins we see (tabs in top navigation bar):\n",
        "\n",
        "* The **Scalars Plugin** shows how our loss and metrics change with every epoch. We can use it to also track our training speed, learning rate, and other scalar values\n",
        "* The **Graphs Plugin** helps us visualize our model. In this case, we see the Keras graph of layers which can help us ensure we built it correctly. \n",
        "* The **Distributions Plugin** and the **Histograms Plugin** show the distribution of a Tensor over time. This can be useful to visualize weights and biases and verify that they are changing in an expected way.\n",
        "\n",
        "Additional TensorBoard plugins are automatically enabled when we log other types of data. For example, the Keras TensorBoard callback lets us write images and embeddings as well. You can see what other plugins are available in TensorBoard by clicking on the \"inactive\" dropdown towards the top right."
      ]
    },
    {
      "metadata": {
        "id": "nB718NOH95yG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using TensorBoard with other methods"
      ]
    },
    {
      "metadata": {
        "id": "IKNt0nWs-Ekt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When training with methods such as with [`tf.GradientTape()`](https://www.tensorflow.org/api_docs/python/tf/GradientTape), use `tf.summary` to log the required information.\n",
        "\n",
        "Use the same dataset as above, but convert it to `tf.data.Dataset` to take advantage of batching capabilities:"
      ]
    },
    {
      "metadata": {
        "id": "nnHx4DsMezy1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(60000).batch(128)\n",
        "test_dataset = test_dataset.batch(128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SzpmTmJafJ10",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The training code is based on the metrics section of the [Effective TensorFlow 2.0](https://github.com/tensorflow/docs/blob/master/site/en/r2/guide/effective_tf2.md) guide:"
      ]
    },
    {
      "metadata": {
        "id": "H2Y5-aPbAANs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "compute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "def train_step(model, optimizer, x_train, y_train):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(x_train, training=True)\n",
        "    loss = compute_loss(y_train, logits)\n",
        "    compute_accuracy(y_train, logits)\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "szw_KrgOg-OT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that `compute_accuracy` is a stateful metric that we can accumulate every train step and log later (see below). \n",
        "\n",
        "Define our training and test functions. Note that we include `tf.summary.scalar()` to log our metrics (loss and accuracy). We have control over which metrics to log and how often we do it."
      ]
    },
    {
      "metadata": {
        "id": "9OvzjHQJBQin",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, dataset, log_freq=50):\n",
        "  avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
        "\n",
        "  for x_train, y_train in dataset:\n",
        "    loss = train_step(model, optimizer, x_train, y_train)\n",
        "    avg_loss(loss)\n",
        "\n",
        "    if tf.equal(optimizer.iterations % log_freq, 0):\n",
        "      tf.summary.scalar('loss', avg_loss.result(), step=optimizer.iterations)\n",
        "      tf.summary.scalar('accuracy', compute_accuracy.result(), step=optimizer.iterations)\n",
        "      print('Step #%d\\tLoss: %.6f' % (optimizer.iterations, loss))\n",
        "    avg_loss.reset_states()\n",
        "    compute_accuracy.reset_states()\n",
        "\n",
        "def test(model, dataset, step_num):\n",
        "  avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
        "\n",
        "  for (x_test, y_test) in dataset:\n",
        "    logits = model(x_test, training=False)\n",
        "    avg_loss(compute_loss(y_test, logits))\n",
        "    compute_accuracy(y_test, logits)\n",
        "  print('Model test set loss: {:0.4f} accuracy: {:0.2f}%'.format(\n",
        "      avg_loss.result(), compute_accuracy.result() * 100))\n",
        "  tf.summary.scalar('loss', avg_loss.result(), step=step_num)\n",
        "  tf.summary.scalar('accuracy', compute_accuracy.result(), step=step_num)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kvbPGxI2hZ4h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train and test our model within the scope of summary writers, which let us write our summaries to disk."
      ]
    },
    {
      "metadata": {
        "id": "0wxFZp8JDXb1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
        "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
        "\n",
        "model = create_model() # reset our model\n",
        "\n",
        "with train_summary_writer.as_default():\n",
        "  train(model, optimizer, train_dataset)\n",
        "\n",
        "with test_summary_writer.as_default():\n",
        "  test(model, test_dataset, optimizer.iterations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fwhsw0zN23wm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Open TensorBoard in same way way but point it at a different log directory. After starting TensorBoard, we can rerun the previous cells to start training again and monitor the training within TensorBoard while it's happening.\n",
        "\n",
        "Unlike our experiments with `Model.fit()`, we are only using the test set at the end of training. We could adapt our code to do multiple epochs and evaluate on the test set at the end of every epoch."
      ]
    },
    {
      "metadata": {
        "id": "g3C-uYK3Dlqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/gradient_tape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BV8O8B1lIg8K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"images/quickstart_gradient_tape.png\"/> -->"
      ]
    },
    {
      "metadata": {
        "id": "ozbwXgPIkCKV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "That's it! We've now seen how to use TensorBoard both through the Keras callback and through `tf.summary` for more custom scenarios. "
      ]
    }
  ]
}