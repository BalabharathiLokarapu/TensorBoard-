{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorboard_profiling_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djUvWu41mtXa",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su2RaORHpReL",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NztQK2uFpXT-",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow Profiler: Profile model performance\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_profiling_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorboard/blob/master/docs/tensorboard_profiling_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDXRFe_qp5C3",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "Machine learning algorithms are typically computationally expensive. It is thus vital to quantify the performance of your machine learning application to ensure that you are running the most optimized version of your model. Use the TensorFlow Profiler to profile the execution of your TensorFlow code. \n",
        "\n",
        "Before you get started, select GPU as the Hardware accelerator in **Edit > Notebook settings**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZhGh-G7KoKL",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpS3QzrHkPia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soSoG6CaRJIy",
        "colab_type": "text"
      },
      "source": [
        "Install the latest version of TensorFlow and import it. TensorBoard profiling requires very recent versions of TensorBoard and TensorFlow; until TensorBoard 2.2 and TensorFlow 2.2 is released we must use a nightly build."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFWOMyaHkUX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uninstall twice to uninstall both the 1.15.0 and 2.1.0 version of TensorFlow and TensorBoard.\n",
        "!pip uninstall -y -q tensorflow tensorboard\n",
        "!pip uninstall -y -q tensorflow tensorboard\n",
        "!pip install -U -q tf-nightly tb-nightly tensorboard_plugin_profile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTbE4iwlkW1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZHbQJzVRfec",
        "colab_type": "text"
      },
      "source": [
        "Confirm that TensorFlow can access the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUGoaffDk9pA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if not device_name:\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsM6wgP9RjEZ",
        "colab_type": "text"
      },
      "source": [
        "## Train an image classification model with TensorBoard callbacks\n",
        "\n",
        "In this tutorial, you explore the capabilities of the TensorFlow Profiler by capturing the performance profile obtained by training a model to classify images in the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co7Bzyoe_3wo",
        "colab_type": "text"
      },
      "source": [
        "Use TensorFlow datasets to import the training data and split it into training and test sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9iGdPe8knMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv5txOxrkq_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME7qce4ZAVHS",
        "colab_type": "text"
      },
      "source": [
        "Preprocess the training and test data by normalizing pixel values to be between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI31gE_3ktiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "ds_train = ds_train.map(normalize_img)\n",
        "ds_train = ds_train.batch(128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vjIX9O8k0fx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_test = ds_test.map(normalize_img)\n",
        "ds_test = ds_test.batch(128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iuvDDOlB6C0",
        "colab_type": "text"
      },
      "source": [
        "Create the image classification model using Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QabMuRcWk2qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.Dense(128,activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeMsDliPC346",
        "colab_type": "text"
      },
      "source": [
        "Create a TensorBoard callback to capture performance profiles and call it while training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkAo1BanlEeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a TensorBoard callback\n",
        "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
        "                                                 histogram_freq = 1,\n",
        "                                                 profile_batch = '500,520')\n",
        "\n",
        "model.fit(ds_train,\n",
        "          epochs=2,\n",
        "          validation_data=ds_test,\n",
        "          callbacks = [tboard_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUk1fuxADbxA",
        "colab_type": "text"
      },
      "source": [
        "## Use the TensorFlow Profiler to profile model training performance\n",
        "\n",
        "The TensorFlow Profiler is embedded within TensorBoard. Load TensorBoard using Colab magic and launch it. View the performance profiles by navigating to the **Profile** tab. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqx5wF1Vlwe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lugpLFAflkeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir=logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5L2PI_RHhW1",
        "colab_type": "text"
      },
      "source": [
        "The **Profile** tab opens the Overview page which shows you a high-level summary of your model performance. Looking at the Step-time Graph on the right, you can see that the model is highly input bound (i.e., it spends a lot of time in the data input piepline). The Overview page also gives you recommendations on potential next steps you can follow to optimize your model performance. \n",
        "\n",
        "To understand where the performance bottleneck occurs in the input pipeline, select the **Trace Viewer** from the **Tools** dropdown on the left. The Trace Viewer shows you a timeline of the different events that occured on the CPU and the GPU during the profiling period. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7KqTo_kUlGX",
        "colab_type": "text"
      },
      "source": [
        "The Trace Viewer shows multiple event groups on the vertical axis. Each event group has multiple horizontal tracks, filled with trace events. The track is an event timeline for events executed on a thread or a GPU stream. Individual events are the colored, rectangular blocks on the timeline tracks. Time moves from left to right. Navigate the trace events by using the keyboard shortcuts `W` (zoom in), `S` (zoom out), `A` (scroll left), and `D` (scroll right).\n",
        "\n",
        "A single rectangle represents a trace event. Select the mouse cursor icon in the floating tool bar (or use the keyboard shortcut `1`) and click the trace event to analyze it. This will display information about the event, such as its start time and duration.\n",
        "\n",
        "In addition to clicking, you can drag the mouse to to select a group of trace events. This will give you a list of all the events in that area along with an event summary. Use the `M` key to measure the time duration of the selected events.\n",
        "\n",
        "Trace events are collected from:\n",
        "\n",
        "*   **CPU:** CPU events are displayed  under an event group named `/host:CPU`. Each track represents a thread on CPU. CPU events include input pipeline events, GPU operation (op) scheduling events, CPU op execution events etc.\n",
        "*   **GPU:** GPU events are displayed under event groups prefixed by `/device:GPU:`. Each event group represents one stream on the GPU. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs9ckIorWs6v",
        "colab_type": "text"
      },
      "source": [
        "## Debug performance bottlenecks\n",
        "\n",
        "Use the Trace Viewer to locate the performance bottlenecks in your input pipeline. The image below is a snapshot of the performance profile. \n",
        "\n",
        "![profiler_trace_viewer_bad_ip](https://github.com/tensorflow/tensorboard/blob/master/docs/images/profiler_trace_viewer_bad_ip.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4rYc-SXYt77",
        "colab_type": "text"
      },
      "source": [
        "Looking at the event traces, you can see that the GPU is inactive while the `tf_data_iterator_get_next` op is running on the CPU. This op is responsible for processing the input data and sending it to the GPU for training. As a general rule of thumb, it is a good idea to always keep the device (GPU/TPU) active."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4KJ3S-odd-a",
        "colab_type": "text"
      },
      "source": [
        "Use the `tf.data` API to optimize the input pipeline. In this case, let's cache the training dataset and prefetch the data to ensure that there is always data available for the GPU to process. See [here](https://www.tensorflow.org/guide/data_performance) for more details on using `tf.data` to optimize your input pipelines. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m5JRkpRLk1Gn",
        "colab": {}
      },
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZWYYeN-aSP4K",
        "colab": {}
      },
      "source": [
        "ds_train = ds_train.map(normalize_img)\n",
        "ds_train = ds_train.batch(128)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9CmH9HkTlF3e",
        "colab": {}
      },
      "source": [
        "ds_test = ds_test.map(normalize_img)\n",
        "ds_test = ds_test.batch(128)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOl8JJBEgWO-",
        "colab_type": "text"
      },
      "source": [
        "Train the model again and capture the performance profile by reusing the callback from before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyOJtCa9gpgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(ds_train,\n",
        "          epochs=2,\n",
        "          validation_data=ds_test,\n",
        "          callbacks = [tboard_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BMwtncTg4r-",
        "colab_type": "text"
      },
      "source": [
        "Re-launch TensorBoard to observe the performance profile for the updated input pipeline. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6B8_DNBhg_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir=logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYCj8WzWhhMf",
        "colab_type": "text"
      },
      "source": [
        "From the Overview page, you can see that the Average Step time has reduced as has the Input Step time. The Step-time Graph also indicates that the model is no longer input bound. Open the Trace Viewer to examine the trace events with the optimized input pipeline.\n",
        "\n",
        "![profiler_trace_viewer_good_ip](https://github.com/tensorflow/tensorboard/blob/master/docs/images/profiler_trace_viewer_good_ip.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93_SDz-1hzYp",
        "colab_type": "text"
      },
      "source": [
        "The Trace Viewer shows that the `tf_data_iterator_get_next` op executes much faster. The GPU therefore gets a steady stream of data to perform training and achieves much better utilization through model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlRwCDoVinHV",
        "colab_type": "text"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Use the TensorFlow Profiler to profile and debug model training performance. Read the [Profiler guide](https://www.tensorflow.org/guide/profiler) to learn more about the various profiling tools and data collection modes available with the TensorFlow Profiler. "
      ]
    }
  ]
}