syntax = "proto3";

package tensorboard.service;

// TODO(bileschi): write_service.proto imports export_service.proto for the
// definition of Experiment and ExperimentMask.  It would be better to excise
// those into one file that both services depend on.
import "tensorboard/uploader/proto/export_service.proto";
import "tensorboard/uploader/proto/scalar.proto";
import "tensorboard/uploader/proto/tensor.proto";
import "tensorboard/compat/proto/summary.proto";

// Service for writing data to TensorBoard.dev.
service TensorBoardWriterService {
  // Request for a new location to write TensorBoard readable events.
  rpc CreateExperiment(CreateExperimentRequest)
      returns (CreateExperimentResponse) {}
  // Request to mutate metadata associated with an experiment.
  rpc UpdateExperiment(UpdateExperimentRequest)
      returns (UpdateExperimentResponse) {}
  // Request that an experiment be deleted, along with all tags and scalars
  // that it contains. This call may only be made by the original owner of the
  // experiment.
  rpc DeleteExperiment(DeleteExperimentRequest)
      returns (DeleteExperimentResponse) {}
  // Request that unreachable data be purged. Used only for testing;
  // disabled in production.
  rpc PurgeData(PurgeDataRequest) returns (PurgeDataResponse) {}
  // Request additional scalar data be stored in TensorBoard.dev.
  rpc WriteScalar(WriteScalarRequest) returns (WriteScalarResponse) {}
  // Request additional tensor data be stored in TensorBoard.dev.
  rpc WriteTensor(WriteTensorRequest) returns (WriteTensorResponse) {}
  // Request to obtain a specific BlobSequence entry, creating it if needed,
  // to be subsequently populated with blobs.
  rpc GetOrCreateBlobSequence(GetOrCreateBlobSequenceRequest)
      returns (GetOrCreateBlobSequenceResponse) {}
  // Request the current status of blob data being stored in TensorBoard.dev,
  // to support resumable uploads.
  rpc GetBlobMetadata(GetBlobMetadataRequest) returns (GetBlobMetadataResponse) {}
  // Request additional blob data be stored in TensorBoard.dev.
  rpc WriteBlob(stream WriteBlobRequest) returns (stream WriteBlobResponse) {}
  // Request that the calling user and all their data be permanently deleted.
  // Used for testing purposes.
  rpc DeleteOwnUser(DeleteOwnUserRequest) returns (DeleteOwnUserResponse) {}
}

// This is currently empty on purpose.  No information is necessary
// to request a URL, except. authorization of course, which doesn't
// come within the proto.
message CreateExperimentRequest {
  // User provided name of the experiment.
  string name = 1;
  // User provided description of the experiment, in markdown source format.
  string description = 2;
}

// Carries all information necessary to:
//  1. Inform the user where to navigate to see their TensorBoard.
//  2. Subsequently load (Scalars, Tensors, etc.) to the specified location.
message CreateExperimentResponse {
  // Service-wide unique identifier of an uploaded log dir.
  // eg: "1r9d0kQkh2laODSZcQXWP"
  string experiment_id = 1;
  // Url the user should navigate to to see their TensorBoard
  // eg: "https://example.com/public/1r9d0kQkh2laODSZcQXWP"
  string url = 2;
}

// Request to change the metadata of one experiment.
message UpdateExperimentRequest {
  // Description of the data to set.  The experiment_id field must match
  // an experiment_id in the database.  The remaining fields should be set
  // to the desired metadata to be written.  Only those fields marked True
  // in the experiment_mask will be written. The service may deny
  // modification of some metadata used for internal bookkeeping, such as
  // num_scalars, etc.
  Experiment experiment = 1;
  // Field mask for what experiment data to set.  The service may deny requests
  // to set some metatadata.
  ExperimentMask experiment_mask = 2;
}

// Response for setting experiment metadata.
message UpdateExperimentResponse {
  // This is empty on purpose.
}

message DeleteExperimentRequest {
  // Service-wide unique identifier of an uploaded log dir.
  // eg: "1r9d0kQkh2laODSZcQXWP"
  string experiment_id = 1;
}

message DeleteExperimentResponse {
  // This is empty on purpose.
}

// Only used for testing; corresponding RPC is disabled in prod.
message PurgeDataRequest {
  // Maximum number of entities of a given kind to purge at once (e.g.,
  // maximum number of tags to purge). Required; must be positive.
  int32 batch_limit = 1;
}

// Only used for testing; corresponding RPC is disabled in prod.
message PurgeDataResponse {
  // Stats about how many elements where purged. Compare to the batch
  // limit specified in the request to estimate whether the backlog has
  // any more items.
  PurgeStats purge_stats = 1;
}

// Details about what actions were taken as a result of a purge request.
// These values are upper bounds; they may exceed the true values.
message PurgeStats {
  // Number of tags deleted as a result of this request.
  int32 tags = 1;
  // Number of experiments marked as purged as a result of this request.
  int32 experiments = 2;
  // Number of users deleted as a result of this request.
  int32 users = 3;
}

// Carries all that is needed to add additional run data to the hosted service.
message WriteScalarRequest {
  // All the data to store for one Run.  This data will be stored under the
  // corresponding run in the hosted storage. WriteScalarRequest is merged into
  // the data store for the keyed run. The tags and included scalars will be
  // the union of the data sent across all WriteScalarRequests. Metadata by
  // default uses a 'first write wins' approach.
  message Run {
    // The name of this run.  For example "/some/path/mnist_experiments/run1/"
    string name = 1;
    // Data to store for this Run/Tag combination.
    repeated Tag tags = 2;
  }

  // All the data to store for one Tag of one Run.  This data will be stored
  // under the corresponding run/tag in the hosted storage. A tag corresponds to
  // a single time series.
  message Tag {
    // The name of this tag.  For example "loss"
    string name = 1;
    // Data to store for this Run/Tag combination.
    repeated ScalarPoint points = 2;
    // The metadata of this tag.
    .tensorboard.SummaryMetadata metadata = 3;
  }

  // Which experiment to write to - corresponding to one hosted TensorBoard URL.
  // The requester must have authorization to write to this location.
  string experiment_id = 1;
  // Data to append to the existing storage at the experiment_id.
  repeated Run runs = 2;
}

// Everything the caller needs to know about how the writing went.
// (Currently empty)
message WriteScalarResponse {
  // This is empty on purpose.
}

// Carries all that is needed to add tensor data to the hosted service.
message WriteTensorRequest {
  // All the data to store for one Run.  This data will be stored under the
  // corresponding run in the hosted storage. WriteTensorRequest is merged into
  // the data store for the keyed run. The tags and included tensors will be
  // the union of the data sent across all WriteTensorRequests. Metadata by
  // default uses a 'first write wins' approach.
  message Run {
    // The name of this run.  For example "/some/path/mnist_experiments/run1/"
    string name = 1;
    // Data to store for this Run/Tag combination.
    repeated Tag tags = 2;
  }

  // All the data to store for one Tag of one Run.  This data will be stored
  // under the corresponding run/tag in the hosted storage. A tag corresponds to
  // a single time series.
  message Tag {
    // The name of this tag.  For example "loss"
    string name = 1;
    // Data to store for this Run/Tag combination.
    repeated TensorPoint points = 2;
    // The metadata of this tag.
    .tensorboard.SummaryMetadata metadata = 3;
  }

  // Which experiment to write to - corresponding to one hosted TensorBoard URL.
  // The requester must have authorization to write to this location.
  string experiment_id = 1;
  // Data to append to the existing storage at the experiment_id.
  repeated Run runs = 2;
}

// Everything the caller needs to know about how the writing went.
// (Currently empty)
message WriteTensorResponse {
  // This is empty on purpose.
}

// The blob sequence writing procedure works as follows:
//  * The caller requests creation of a new BlobSequence, via the
//    GetOrCreateBlobSequence RPC. The response provides a new BlobSequence ID.
//  * The caller writes each blob in the sequence separately via the WriteBlob
//    RPC as described below, providing the blob sequence ID and sequence index
//    for each blob.
//  * Multiple WriteBlob streams may operate in parallel (for different blobs),
//    with no constraint on their ordering.

// Blob sequence uploads are resumable, as follows:
//  * The client starts the upload process with a new GetOrCreateBlobSequence
//    RPC.
//  * The blob sequences are uniquely keyed by experiment, run, tag, and step.
//    Since this is a second (or later) attempt regarding an existing sequence,
//    a new sequence is not created.  Instead the existing sequence ID is
//    returned.
//  * The client attempts to upload each blob in the sequence.  These uploads
//    resume or may be skipped entirely, as needed, according to the below
//    procedure.

// The blob writing procedure is as follows.  It is intrinsically resumable.
//  * The caller instantiates a WriteBlob RPC, which is a bidirectional stream.
//  * The caller sends one or more WriteBlobRequests, providing the blob data
//    in an ordered sequence of chunks.
//  * The caller receives a sequence of WriteBlobResponses in return. Each
//    WriteBlobResponse corresponds to one WriteBlobRequest in order, reporting
//    the state of the write operation.
//  * The streams need not operate in 'ping-pong' style-- i.e. the client may
//    continue to send requests, regardless of whether responses to prior
//    requests have arrived yet.
//
//  * A request sent over the stream may optionally contain no actual
//    data. In this case it acts only as a request for the current status of
//    the blob. For instance, the client may send such a query as the first
//    request, to learn whether the blob has already been partially or fully
//    uploaded.
//  * In response to such a query, the WriteBlobResponse reports the state,
//    size, and crc32c of the object so far, i.e. taking into account any
//    previously uploaded data.  (Note that the crc32c field must be populated
//    only in response to these query requests, not in reponse to requests that
//    contain data.)
//  * The client proceeds to upload from the specified offset (optionally
//    validating the crc32c up to that point first).  Of course, if the object
//    is already finalized, then nothing remains to upload, so the stream
//    closes.
//  * If the first request does provide data, that chunk may turn out to be
//    redundant with a previous partial upload.  This will produce an error,
//    closing the stream.  At this point the client should start a new stream
//    with an empty 'query' request, allowing it to resume the upload at the
//    correct offset. It is up to the client to
//    weigh the tradeoff between this possibly-wasted transfer and an
//    additional initial roundtrip to obtain the status.
//
//  * For requests that include data, the response may not populate the crc32c
//    field. In general, the caller should not wait to verify that each response
//    reports the expected status and size before sending the next request.
//    Doing so reduces throughput, with little benefit since any mismatch on the
//    server side will cause the RPC to throw an error anyway.
//  * Nonetheless the caller may wish to validate these values, if provided,
//    whenever the response does arrive.
//  * The request size should be less than 4 MiB (2^20 = 4,194,304), because
//    that is the default request limit for gRPC. Accounting for the other
//    fields of the request, then, and leaving some padding for safety, the data
//    chunk should be somewhat smaller-- perhaps simply 4e6 bytes.
//  * The last of these requests must set finalize_object=True, and the prior
//    ones must not.
//  * For a blob <= 4MB, a single request suffices (assuming no empty status
//    request), so it is both the first and the last chunk.
//
// Note that the WriteBlobRequest does not mirror the nested structure of
// WriteScalarRequest, because we only ever send one blob at a time.

// Obtain a unique ID for a blob sequence, given the composite key
// (experiment_id, run, tag, step).  If such a blob sequence already exists,
// return its ID.  If not, create it first, and return the new ID.
message GetOrCreateBlobSequenceRequest {
  // Service-wide unique identifier of an uploaded log dir.
  // eg: "1r9d0kQkh2laODSZcQXWP"
  string experiment_id = 1;
  // The name of the run to which the blob sequence belongs, for example
  // "/some/path/mnist_experiments/run1/".
  string run = 2;
  // The name of the tag to which the blob sequence belongs, for example "loss".
  string tag = 3;
  // Step index within the run.
  int64 step = 4;
  // The total number of elements expected in the sequence.
  // This effectively delares a number of initially empty 'upload slots',
  // to be filled with subsequent WriteBlob RPCs.
  int64 final_sequence_length = 5;
  // Note that metadata.plugin_data.content does not carry the payload.
  .tensorboard.SummaryMetadata metadata = 6;
}

message GetOrCreateBlobSequenceResponse {
  // A unique ID for the the requested blob sequence.
  string blob_sequence_id = 1;
}

enum BlobState {
    // Object state is unknown. This value should never be used; it is present
    // only as a proto3 best practice.
    // See https://developers.google.com/protocol-buffers/docs/proto3#enum
    UNKNOWN = 0;

    // Object is being written and not yet finalized.
    UNFINALIZED = 1;

    // Object is finalized.
    CURRENT = 2;
  }

message GetBlobMetadataRequest {
  // The ID of the BlobSequence of which this blob is a member.
  string blob_sequence_id = 1;
  // The position of this Blob within the BlobSequence
  int64 index = 2;
}

message GetBlobMetadataResponse {
  // State of the object (still appending vs. complete).
  BlobState object_state = 1;
  // Size of the object in bytes.  This is the sum of the chunk sizes
  // received from the stream so far.  In the response to the final chunk,
  // this size should equal the total size of the blob.
  int64 size = 2;
}

// A single chunk of the blob write stream.
message WriteBlobRequest {
  // The ID of the BlobSequence of which this blob is a member.
  string blob_sequence_id = 1;
  // The position of this Blob within the BlobSequence
  int64 index = 2;
  // The bytes in this chunk.  For the first chunk only, this field is optional.
  // Leaving it empty allows determining from the response how much of the blob
  // has already been uploaded, if any, without sending redundant data.
  bytes data = 3;
  // The position in the blob where this chunk begins.
  // This must equal the sum of the sizes of the chunks sent so far.  Ignored
  // if no data is provided.
  int64 offset = 4;
  // CRC32C of current data buffer. Clients must include the crc32c for every
  // data buffer, to protect against data corruption.  Note that for multi-shot
  // writes, specifying the crc32c for every data buffer provides stronger
  // protection than just providing the final_crc32c at the end of the upload.
  fixed32 crc32c = 5;
  // Indicates that this is the last chunk of the stream.
  bool finalize_object = 6;
  // CRC32C of the entire blob.  Required, to protect against data corruption.
  // This should be set only when finalize_object=True.
  fixed32 final_crc32c = 7;
}

message WriteBlobResponse {
  // State of the object (still appending vs. complete).
  BlobState blob_state = 1;
  // Size of the object in bytes.  This is the sum of the chunk sizes
  // received from the stream so far.  In the response to the final chunk,
  // this size should equal the total size of the blob.
  int64 size = 2;
}

// Requests that the calling user and all their data be permanently deleted.
message DeleteOwnUserRequest {
  // This is empty on purpose.
}

// Everything the caller needs to know about how the deletion went.
message DeleteOwnUserResponse {
  // This is empty on purpose.
}
